#!/usr/bin/python3import nltk as nlfrom nltk.corpus import stopwordsfrom nltk.stem import PorterStemmerdef request_processing(self):    cleaned = remove_noise(self)    print(cleaned)    stemmed = stem_words(cleaned)    tagged = tagging(stemmed)    print(tagged)    objects, intents = sorting_words(tagged)    return objects, intentsdef remove_noise(self):    print("---------------------------------")    print("Removing Noise words")    words = nl.word_tokenize(self)    clean_words = words    sr = stopwords.words('english')    for word in words:        if word in sr:            clean_words.remove(word)    return clean_words# Removes word endings to reveal the core word# Example: Sadly will have "ly" removed to form saddef stem_words(self):    ps = PorterStemmer()    stemmed = []    for word in self:        stemmed.append(ps.stem(word))    return stemmed# This tags the individual words within the processed text# Places a tag as to whether the word is a noun, verb, adjective etcdef tagging(self):    tagged = nl.pos_tag(self)    return tagged# This function sorts the tagged words into objects and intents# Verb words are intents and Nouns are objectsdef sorting_words(self):    objects = []    intents = []    for line in self:        if line[1] == "NN" or line[1] == "CD":            objects.append(line[0])        elif line[1] == "VBN" or line[1] == "VB" or line[1] == "WP" or line[1] == "WRB":            intents.append(line[0])    return objects, intents